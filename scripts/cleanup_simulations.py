#!/usr/bin/env python3
"""
P1-E2: ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ TTL/ë³´ê´€ ì •ì±… ìŠ¤í¬ë¦½íŠ¸

ì €ì¥ ë¹„ìš©/ê°œì¸ì •ë³´ ìœ„í—˜ ìµœì†Œí™”ë¥¼ ìœ„í•´ ë§Œë£Œëœ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.

## TTL ì •ì±…

| í…Œì´ë¸”           | ê¸°ë³¸ ë³´ê´€ ê¸°ê°„ | ì„¤ëª…                                |
|------------------|----------------|-------------------------------------|
| simulation_run   | 90ì¼           | ìš”ì²­ ë©”íƒ€ë°ì´í„°                     |
| simulation_path  | 90ì¼           | ì¼ë³„ NAV ê²½ë¡œ (runê³¼ í•¨ê»˜ ì‚­ì œ)      |
| simulation_summary| 1ë…„           | ìš”ì•½ ì§€í‘œ (runê³¼ í•¨ê»˜ ì‚­ì œ)          |

## ì‚­ì œ ê¸°ì¤€
- simulation_run.expires_at < í˜„ì¬ì‹œê°„ ì¸ ë ˆì½”ë“œ ì‚­ì œ
- CASCADEë¡œ path, summary ìë™ ì‚­ì œ

Usage:
    # ë“œë¼ì´ëŸ° (ì‚­ì œ ëŒ€ìƒ í™•ì¸ë§Œ)
    python scripts/cleanup_simulations.py --dry-run

    # ì‹¤ì œ ì‚­ì œ ì‹¤í–‰
    python scripts/cleanup_simulations.py

    # ë°°ì¹˜ í¬ê¸° ì§€ì • (ëŒ€ëŸ‰ ë°ì´í„°)
    python scripts/cleanup_simulations.py --batch-size 500

    # íŠ¹ì • ë‚ ì§œ ê¸°ì¤€ ì‚­ì œ (í…ŒìŠ¤íŠ¸ìš©)
    python scripts/cleanup_simulations.py --before 2025-01-01

    # ì•„ì¹´ì´ë¸Œ í›„ ì‚­ì œ
    python scripts/cleanup_simulations.py --archive /path/to/archive

ìš´ì˜ ì ˆì°¨:
    1. ë§¤ì¼ ìƒˆë²½ cronìœ¼ë¡œ ë“œë¼ì´ëŸ° ì‹¤í–‰ (ì•Œë¦¼ìš©)
    2. ì£¼ 1íšŒ ì‹¤ì œ ì‚­ì œ ì‹¤í–‰
    3. ì‚­ì œ ì „ --archive ì˜µì…˜ìœ¼ë¡œ ë°±ì—… ê¶Œì¥
"""

import argparse
import sys
import os
import json
import gzip
from datetime import datetime, date, timedelta
from typing import Optional, List, Dict

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
os.chdir(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from sqlalchemy import create_engine, text, func
from sqlalchemy.orm import sessionmaker


# ============================================================================
# TTL ì •ì±… ì •ì˜
# ============================================================================

DEFAULT_TTL_POLICY = {
    "simulation_run": 90,      # 90ì¼ (ê¸°ë³¸ê°’, expires_at ì»¬ëŸ¼ ì‚¬ìš©)
    "simulation_path": 90,     # runê³¼ í•¨ê»˜ CASCADE ì‚­ì œ
    "simulation_summary": 365, # 1ë…„ (ì°¸ê³ ìš©, ì‹¤ì œë¡œëŠ” runê³¼ í•¨ê»˜ ì‚­ì œ)
}


def get_database_url() -> str:
    """í™˜ê²½ë³€ìˆ˜ì—ì„œ DATABASE_URL ê°€ì ¸ì˜¤ê¸°"""
    db_url = os.getenv("DATABASE_URL")
    if not db_url:
        print("âŒ DATABASE_URL í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        sys.exit(1)
    return db_url


def get_expired_runs_count(engine, before_date: datetime = None) -> int:
    """ë§Œë£Œëœ ì‹œë®¬ë ˆì´ì…˜ run ìˆ˜ ì¡°íšŒ"""
    if before_date is None:
        before_date = datetime.utcnow()

    with engine.connect() as conn:
        result = conn.execute(text("""
            SELECT COUNT(*) FROM simulation_run
            WHERE expires_at IS NOT NULL AND expires_at < :before_date
        """), {"before_date": before_date})
        return result.scalar() or 0


def get_expired_runs(
    engine,
    before_date: datetime = None,
    limit: int = 100,
    offset: int = 0
) -> List[Dict]:
    """ë§Œë£Œëœ ì‹œë®¬ë ˆì´ì…˜ run ëª©ë¡ ì¡°íšŒ"""
    if before_date is None:
        before_date = datetime.utcnow()

    with engine.connect() as conn:
        result = conn.execute(text("""
            SELECT
                run_id,
                request_hash,
                scenario_id,
                start_date,
                end_date,
                created_at,
                expires_at,
                (SELECT COUNT(*) FROM simulation_path WHERE run_id = simulation_run.run_id) as path_count
            FROM simulation_run
            WHERE expires_at IS NOT NULL AND expires_at < :before_date
            ORDER BY expires_at ASC
            LIMIT :limit OFFSET :offset
        """), {"before_date": before_date, "limit": limit, "offset": offset})

        return [
            {
                "run_id": row[0],
                "request_hash": row[1],
                "scenario_id": row[2],
                "start_date": row[3].isoformat() if row[3] else None,
                "end_date": row[4].isoformat() if row[4] else None,
                "created_at": row[5].isoformat() if row[5] else None,
                "expires_at": row[6].isoformat() if row[6] else None,
                "path_count": row[7]
            }
            for row in result.fetchall()
        ]


def archive_simulation_run(engine, run_id: int) -> Dict:
    """
    ì‹œë®¬ë ˆì´ì…˜ runì„ JSONìœ¼ë¡œ ì•„ì¹´ì´ë¸Œ

    Returns:
        ì•„ì¹´ì´ë¸Œëœ ë°ì´í„° dict
    """
    with engine.connect() as conn:
        # run ì¡°íšŒ
        run_result = conn.execute(text("""
            SELECT * FROM simulation_run WHERE run_id = :run_id
        """), {"run_id": run_id})
        run_row = run_result.fetchone()
        if not run_row:
            return None

        run_keys = run_result.keys()
        run_data = dict(zip(run_keys, run_row))

        # summary ì¡°íšŒ
        summary_result = conn.execute(text("""
            SELECT * FROM simulation_summary WHERE run_id = :run_id
        """), {"run_id": run_id})
        summary_row = summary_result.fetchone()
        summary_data = None
        if summary_row:
            summary_keys = summary_result.keys()
            summary_data = dict(zip(summary_keys, summary_row))

        # path ì¡°íšŒ
        path_result = conn.execute(text("""
            SELECT * FROM simulation_path WHERE run_id = :run_id ORDER BY path_date
        """), {"run_id": run_id})
        path_rows = path_result.fetchall()
        path_keys = path_result.keys()
        path_data = [dict(zip(path_keys, row)) for row in path_rows]

    # datetime/date/Decimalì„ ë¬¸ìì—´ë¡œ ë³€í™˜
    def serialize(obj):
        if isinstance(obj, (datetime, date)):
            return obj.isoformat()
        elif hasattr(obj, '__float__'):
            return float(obj)
        return obj

    def serialize_dict(d):
        if d is None:
            return None
        return {k: serialize(v) for k, v in d.items()}

    return {
        "run": serialize_dict(run_data),
        "summary": serialize_dict(summary_data),
        "paths": [serialize_dict(p) for p in path_data],
        "archived_at": datetime.utcnow().isoformat()
    }


def delete_simulation_run(engine, run_id: int) -> bool:
    """
    ì‹œë®¬ë ˆì´ì…˜ run ì‚­ì œ (CASCADEë¡œ path, summary í•¨ê»˜ ì‚­ì œ)
    """
    with engine.connect() as conn:
        result = conn.execute(text("""
            DELETE FROM simulation_run WHERE run_id = :run_id
        """), {"run_id": run_id})
        conn.commit()
        return result.rowcount > 0


def run_cleanup(
    before_date: datetime = None,
    batch_size: int = 100,
    dry_run: bool = False,
    archive_path: str = None,
    verbose: bool = True
) -> Dict:
    """
    ë§Œë£Œëœ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ì •ë¦¬

    Args:
        before_date: ì´ ë‚ ì§œ ì´ì „ expires_atì¸ ë ˆì½”ë“œ ì‚­ì œ (ê¸°ë³¸: í˜„ì¬ì‹œê°„)
        batch_size: ë°°ì¹˜ ë‹¹ ì²˜ë¦¬ ê±´ìˆ˜
        dry_run: Trueë©´ ì‹¤ì œ ì‚­ì œ ì—†ì´ í™•ì¸ë§Œ
        archive_path: ì•„ì¹´ì´ë¸Œ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ì§€ì • ì‹œ ì‚­ì œ ì „ ë°±ì—…)
        verbose: ìƒì„¸ ì¶œë ¥

    Returns:
        ê²°ê³¼ í†µê³„
    """
    db_url = get_database_url()
    engine = create_engine(db_url)

    if before_date is None:
        before_date = datetime.utcnow()

    if verbose:
        print("=" * 60)
        print("ğŸ§¹ Foresto Phase 1 - ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ì •ë¦¬")
        print("=" * 60)
        print(f"ğŸ“… ê¸°ì¤€ ì‹œê°„: {before_date.isoformat()}")
        print(f"ğŸ“¦ ë°°ì¹˜ í¬ê¸°: {batch_size}")
        print(f"ğŸ” ëª¨ë“œ: {'ë“œë¼ì´ëŸ° (í™•ì¸ë§Œ)' if dry_run else 'ì‹¤í–‰'}")
        if archive_path:
            print(f"ğŸ“ ì•„ì¹´ì´ë¸Œ: {archive_path}")
        print()

    # ë§Œë£Œ ëŒ€ìƒ ìˆ˜ ì¡°íšŒ
    total_expired = get_expired_runs_count(engine, before_date)

    if verbose:
        print(f"ğŸ“Š ë§Œë£Œëœ ì‹œë®¬ë ˆì´ì…˜: {total_expired}ê±´")
        print()

    if total_expired == 0:
        if verbose:
            print("âœ… ì‚­ì œí•  ë ˆì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return {
            "total_expired": 0,
            "deleted": 0,
            "archived": 0,
            "failed": 0
        }

    # ì•„ì¹´ì´ë¸Œ ë””ë ‰í† ë¦¬ ìƒì„±
    if archive_path and not dry_run:
        os.makedirs(archive_path, exist_ok=True)

    # ë°°ì¹˜ ì²˜ë¦¬
    deleted_count = 0
    archived_count = 0
    failed_count = 0
    offset = 0

    while True:
        # ë°°ì¹˜ ì¡°íšŒ (ì‚­ì œ í›„ offset ìœ ì§€ - ìˆœì°¨ ì‚­ì œì´ë¯€ë¡œ)
        batch = get_expired_runs(engine, before_date, batch_size, 0 if not dry_run else offset)

        if not batch:
            break

        if verbose and not dry_run:
            print(f"ğŸ“‹ ë°°ì¹˜ ì²˜ë¦¬: {len(batch)}ê±´")

        for run_info in batch:
            run_id = run_info["run_id"]

            if verbose:
                scenario = run_info.get("scenario_id") or "custom"
                path_count = run_info.get("path_count", 0)
                expires = run_info.get("expires_at", "N/A")
                print(f"  - run_id={run_id} scenario={scenario} "
                      f"paths={path_count} expires={expires}")

            if dry_run:
                offset += 1
                continue

            try:
                # ì•„ì¹´ì´ë¸Œ
                if archive_path:
                    archive_data = archive_simulation_run(engine, run_id)
                    if archive_data:
                        archive_file = os.path.join(
                            archive_path,
                            f"sim_run_{run_id}_{datetime.utcnow().strftime('%Y%m%d')}.json.gz"
                        )
                        with gzip.open(archive_file, 'wt', encoding='utf-8') as f:
                            json.dump(archive_data, f, ensure_ascii=False, indent=2)
                        archived_count += 1

                # ì‚­ì œ
                if delete_simulation_run(engine, run_id):
                    deleted_count += 1
                else:
                    failed_count += 1

            except Exception as e:
                print(f"  âŒ run_id={run_id} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                failed_count += 1

        if dry_run:
            # ë“œë¼ì´ëŸ°ì—ì„œëŠ” offsetìœ¼ë¡œ ë‹¤ìŒ í˜ì´ì§€
            if len(batch) < batch_size:
                break
        else:
            # ì‹¤ì œ ì‚­ì œì—ì„œëŠ” ì²« ë²ˆì§¸ ë°°ì¹˜ ë°˜ë³µ
            if deleted_count + failed_count >= total_expired:
                break

    # ê²°ê³¼ ìš”ì•½
    result = {
        "total_expired": total_expired,
        "deleted": deleted_count,
        "archived": archived_count,
        "failed": failed_count,
        "before_date": before_date.isoformat()
    }

    if verbose:
        print()
        print("=" * 60)
        print("ğŸ“Š ê²°ê³¼ ìš”ì•½")
        print("=" * 60)
        print(f"  ì´ ë§Œë£Œ: {total_expired}ê±´")
        print(f"  ì‚­ì œë¨: {deleted_count}ê±´")
        if archive_path:
            print(f"  ì•„ì¹´ì´ë¸Œë¨: {archived_count}ê±´")
        print(f"  ì‹¤íŒ¨: {failed_count}ê±´")

        if dry_run:
            print()
            print("ğŸ’¡ --dry-run í”Œë˜ê·¸ë¥¼ ì œê±°í•˜ê³  ë‹¤ì‹œ ì‹¤í–‰í•˜ë©´ ì‹¤ì œë¡œ ì‚­ì œë©ë‹ˆë‹¤.")
        else:
            print()
            print("âœ… ì •ë¦¬ ì™„ë£Œ")

    return result


def show_retention_stats(verbose: bool = True) -> Dict:
    """í˜„ì¬ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ë³´ê´€ í˜„í™© ì¶œë ¥"""
    db_url = get_database_url()
    engine = create_engine(db_url)

    with engine.connect() as conn:
        # ì „ì²´ í†µê³„
        total_runs = conn.execute(text("SELECT COUNT(*) FROM simulation_run")).scalar() or 0
        total_paths = conn.execute(text("SELECT COUNT(*) FROM simulation_path")).scalar() or 0
        total_summaries = conn.execute(text("SELECT COUNT(*) FROM simulation_summary")).scalar() or 0

        # ë§Œë£Œ ì˜ˆì •
        now = datetime.utcnow()
        expired = conn.execute(text("""
            SELECT COUNT(*) FROM simulation_run
            WHERE expires_at IS NOT NULL AND expires_at < :now
        """), {"now": now}).scalar() or 0

        # 7ì¼ ë‚´ ë§Œë£Œ ì˜ˆì •
        week_later = now + timedelta(days=7)
        expiring_soon = conn.execute(text("""
            SELECT COUNT(*) FROM simulation_run
            WHERE expires_at IS NOT NULL AND expires_at >= :now AND expires_at < :week
        """), {"now": now, "week": week_later}).scalar() or 0

        # ì‹œë‚˜ë¦¬ì˜¤ë³„ ë¶„í¬
        scenario_dist = conn.execute(text("""
            SELECT
                COALESCE(scenario_id, 'custom') as scenario,
                COUNT(*) as count
            FROM simulation_run
            GROUP BY scenario_id
            ORDER BY count DESC
            LIMIT 10
        """)).fetchall()

    stats = {
        "total_runs": total_runs,
        "total_paths": total_paths,
        "total_summaries": total_summaries,
        "expired": expired,
        "expiring_in_7_days": expiring_soon,
        "by_scenario": [(row[0], row[1]) for row in scenario_dist]
    }

    if verbose:
        print("=" * 60)
        print("ğŸ“Š ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ë³´ê´€ í˜„í™©")
        print("=" * 60)
        print(f"  simulation_run: {total_runs}ê±´")
        print(f"  simulation_path: {total_paths}ê±´")
        print(f"  simulation_summary: {total_summaries}ê±´")
        print()
        print(f"  â° ë§Œë£Œë¨ (ì‚­ì œ ëŒ€ìƒ): {expired}ê±´")
        print(f"  âš ï¸  7ì¼ ë‚´ ë§Œë£Œ ì˜ˆì •: {expiring_soon}ê±´")
        print()
        print("  ì‹œë‚˜ë¦¬ì˜¤ë³„ ë¶„í¬:")
        for scenario, count in stats["by_scenario"]:
            print(f"    - {scenario}: {count}ê±´")

    return stats


def main():
    parser = argparse.ArgumentParser(
        description="ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ TTL/ë³´ê´€ ì •ì±… ê´€ë¦¬ (P1-E2)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
TTL ì •ì±…:
  - simulation_run: 90ì¼ (expires_at ì»¬ëŸ¼ ê¸°ì¤€)
  - simulation_path: runê³¼ í•¨ê»˜ CASCADE ì‚­ì œ
  - simulation_summary: runê³¼ í•¨ê»˜ CASCADE ì‚­ì œ

ì˜ˆì‹œ:
  # ì‚­ì œ ëŒ€ìƒ í™•ì¸ (ë“œë¼ì´ëŸ°)
  python scripts/cleanup_simulations.py --dry-run

  # ì‹¤ì œ ì‚­ì œ ì‹¤í–‰
  python scripts/cleanup_simulations.py

  # ì•„ì¹´ì´ë¸Œ í›„ ì‚­ì œ
  python scripts/cleanup_simulations.py --archive ./archive

  # í˜„ì¬ ë³´ê´€ í˜„í™© í™•ì¸
  python scripts/cleanup_simulations.py --stats

ìš´ì˜ ì ˆì°¨:
  1. ë§¤ì¼: python scripts/cleanup_simulations.py --stats
  2. ì£¼ 1íšŒ: python scripts/cleanup_simulations.py --archive ./backup
        """
    )

    parser.add_argument(
        "--dry-run", "-n",
        action="store_true",
        help="ì‹¤ì œ ì‚­ì œ ì—†ì´ ëŒ€ìƒ í™•ì¸ë§Œ"
    )
    parser.add_argument(
        "--batch-size", "-b",
        type=int,
        default=100,
        help="ë°°ì¹˜ ë‹¹ ì²˜ë¦¬ ê±´ìˆ˜ (ê¸°ë³¸: 100)"
    )
    parser.add_argument(
        "--before",
        type=str,
        help="ì´ ë‚ ì§œ ì´ì „ ë§Œë£Œëœ ë ˆì½”ë“œ ì‚­ì œ (YYYY-MM-DD, ê¸°ë³¸: í˜„ì¬ì‹œê°„)"
    )
    parser.add_argument(
        "--archive", "-a",
        type=str,
        help="ì‚­ì œ ì „ ì•„ì¹´ì´ë¸Œí•  ë””ë ‰í† ë¦¬ ê²½ë¡œ"
    )
    parser.add_argument(
        "--stats", "-s",
        action="store_true",
        help="ë³´ê´€ í˜„í™©ë§Œ ì¶œë ¥"
    )
    parser.add_argument(
        "--quiet", "-q",
        action="store_true",
        help="ìµœì†Œ ì¶œë ¥"
    )

    args = parser.parse_args()

    if args.stats:
        show_retention_stats(verbose=not args.quiet)
        return

    # ë‚ ì§œ íŒŒì‹±
    before_date = None
    if args.before:
        try:
            before_date = datetime.strptime(args.before, "%Y-%m-%d")
        except ValueError:
            print(f"âŒ ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {args.before}")
            print("   YYYY-MM-DD í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
            sys.exit(1)

    result = run_cleanup(
        before_date=before_date,
        batch_size=args.batch_size,
        dry_run=args.dry_run,
        archive_path=args.archive,
        verbose=not args.quiet
    )

    # ì‹¤íŒ¨ê°€ ìˆìœ¼ë©´ exit code 1
    if result.get("failed", 0) > 0:
        sys.exit(1)


if __name__ == "__main__":
    main()
